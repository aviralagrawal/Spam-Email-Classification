{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Model1SingleDirectionalLSTM&TokenizerWholeDataset",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Vn7sB1kNiyjc",
        "colab_type": "code",
        "outputId": "85771b7e-ef94-4673-e0df-99ac11accf85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import re\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Brn9ZLz70he",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J42b4Us_i2t5",
        "colab_type": "code",
        "outputId": "5697722f-da3f-4144-d5b3-2144c38aba7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_L6Xb9vElOdN",
        "colab_type": "code",
        "outputId": "d110b3b0-7e9f-4ffb-9f7e-49c5162e3a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zK6WvrLxla_x",
        "colab_type": "code",
        "outputId": "2d9db800-8dd1-4c4d-b516-89decae83aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd gdrive/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hWjXbFXtley8",
        "colab_type": "code",
        "outputId": "9ddc7756-5822-4fe0-d4d0-0fcf0ee01734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ICd7orgGlfue",
        "colab_type": "code",
        "outputId": "b16ebecf-7bf8-410d-9fb4-dd4ded91fcd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "waeupe7qlhgP",
        "colab_type": "code",
        "outputId": "6aa0489f-d543-4e69-ea56-a28d45ba1346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " A1_csv.rar                   'Popl Assignment.gdoc'\n",
            " A1.pdf                        \u001b[0m\u001b[01;34msopdata\u001b[0m/\n",
            "'Aviral Resume New.pdf'        \u001b[01;34mspamdata\u001b[0m/\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/            'TA Groups.xlsx'\n",
            "\u001b[01;34m'Data Science Hackathon'\u001b[0m/     'TIMETABLE SEM II 2015-16 (11 JAN 2016).pdf'\n",
            " \u001b[01;34mMNIST_Data\u001b[0m/                   TRAIN_FINAL.csv.zip\n",
            " model_weights.h5              \u001b[01;34mtraining\u001b[0m/\n",
            "\u001b[01;34m'NNFL Lab1'\u001b[0m/                   \u001b[01;34mTraining\u001b[0m/\n",
            "\u001b[01;34m'NNFL Project'\u001b[0m/                Training.zip\n",
            "'NNFL_Scratch Aashish.ipynb'   Untitled1.ipynb\n",
            " OUTING.docx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aXLTkv25ljb8",
        "colab_type": "code",
        "outputId": "a7a6fdc6-d646-40d8-afbe-9b00e40d5e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd spamdata/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/spamdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ihJUX_-3ll7b",
        "colab_type": "code",
        "outputId": "846c1b29-14ef-421c-dac7-79375b0802a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        }
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "i = 0\n",
        "\n",
        "for filename in os.listdir(r'ham/'):\n",
        "    path = \"ham\"+\"/\" + filename\n",
        "    file = open(path,errors='ignore')\n",
        "    data = file.read()\n",
        "#     if(type(re.search('Content(.*\\n)*',data))!='NoneType'):\n",
        "#         dat = re.search('Content(.*\\n)*',data)\n",
        "#         if dat is not None:\n",
        "#             dat = dat.group()\n",
        "    X.append(data)\n",
        "    Y.append('ham')\n",
        "    i=i+1\n",
        "    if(i%10==0):\n",
        "        print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-24ca99cfa3aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ham\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     if(type(re.search('Content(.*\\n)*',data))!='NoneType'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         dat = re.search('Content(.*\\n)*',data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JqtU0CdAl2BE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9deq89AAmKNE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for filename in os.listdir(r'spam/'):\n",
        "    path = \"spam\"+\"/\" + filename\n",
        "    file = open(path,errors='ignore')\n",
        "    data = file.read()\n",
        "#     if(type(re.search('Content(.*\\n)*',data))!='NoneType'):\n",
        "#         dat = re.search('Content(.*\\n)*',data)\n",
        "#         if dat is not None:\n",
        "#             dat = dat.group()\n",
        "    X.append(data)\n",
        "    Y.append('spam')\n",
        "    i=i+1\n",
        "    if(i%10==0):\n",
        "        print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcVIL66umRMa",
        "colab_type": "code",
        "outputId": "80a382b9-721f-4f42-bbb1-acea4c06a130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1486
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(X[2])\n",
        "print(Y[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3053\n",
            "From Stewart.Smith@ee.ed.ac.uk  Thu Aug 22 14:44:26 2002\n",
            "Return-Path: <Stewart.Smith@ee.ed.ac.uk>\n",
            "Delivered-To: zzzz@localhost.netnoteinc.com\n",
            "Received: from localhost (localhost [127.0.0.1])\n",
            "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id EC69D47C66\n",
            "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 09:44:25 -0400 (EDT)\n",
            "Received: from phobos [127.0.0.1]\n",
            "\tby localhost with IMAP (fetchmail-5.9.0)\n",
            "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 14:44:25 +0100 (IST)\n",
            "Received: from n6.grp.scd.yahoo.com (n6.grp.scd.yahoo.com [66.218.66.90])\n",
            "    by dogma.slashnull.org (8.11.6/8.11.6) with SMTP id g7MDcOZ08504 for\n",
            "    <zzzz@example.com>; Thu, 22 Aug 2002 14:38:25 +0100\n",
            "X-Egroups-Return: sentto-2242572-52736-1030023506-zzzz=example.com@returns.groups.yahoo.com\n",
            "Received: from [66.218.67.192] by n6.grp.scd.yahoo.com with NNFMP;\n",
            "    22 Aug 2002 13:38:26 -0000\n",
            "X-Sender: Stewart.Smith@ee.ed.ac.uk\n",
            "X-Apparently-To: zzzzteana@yahoogroups.com\n",
            "Received: (EGP: mail-8_1_0_1); 22 Aug 2002 13:38:25 -0000\n",
            "Received: (qmail 48882 invoked from network); 22 Aug 2002 13:38:25 -0000\n",
            "Received: from unknown (66.218.66.218) by m10.grp.scd.yahoo.com with QMQP;\n",
            "    22 Aug 2002 13:38:25 -0000\n",
            "Received: from unknown (HELO postbox.ee.ed.ac.uk) (129.215.80.253) by\n",
            "    mta3.grp.scd.yahoo.com with SMTP; 22 Aug 2002 13:38:24 -0000\n",
            "Received: from ee.ed.ac.uk (sxs@dunblane [129.215.34.86]) by\n",
            "    postbox.ee.ed.ac.uk (8.11.0/8.11.0) with ESMTP id g7MDcNi28645 for\n",
            "    <forteana@yahoogroups.com>; Thu, 22 Aug 2002 14:38:23 +0100 (BST)\n",
            "Message-Id: <3D64E94E.8060301@ee.ed.ac.uk>\n",
            "Organization: Scottish Microelectronics Centre\n",
            "User-Agent: Mozilla/5.0 (X11; U; SunOS sun4u; en-US; rv:1.1b) Gecko/20020628\n",
            "X-Accept-Language: en, en-us\n",
            "To: zzzzteana@yahoogroups.com\n",
            "References: <3D64F325.11319.61EA648@localhost>\n",
            "From: Stewart Smith <Stewart.Smith@ee.ed.ac.uk>\n",
            "X-Yahoo-Profile: stochasticus\n",
            "MIME-Version: 1.0\n",
            "Mailing-List: list zzzzteana@yahoogroups.com; contact\n",
            "    forteana-owner@yahoogroups.com\n",
            "Delivered-To: mailing list zzzzteana@yahoogroups.com\n",
            "Precedence: bulk\n",
            "List-Unsubscribe: <mailto:zzzzteana-unsubscribe@yahoogroups.com>\n",
            "Date: Thu, 22 Aug 2002 14:38:22 +0100\n",
            "Subject: Re: [zzzzteana] Nothing like mama used to make\n",
            "Reply-To: zzzzteana@yahoogroups.com\n",
            "Content-Type: text/plain; charset=US-ASCII\n",
            "Content-Transfer-Encoding: 7bit\n",
            "\n",
            ">  in adding cream to spaghetti carbonara, which has the same effect on pasta as\n",
            ">  making a pizza a deep-pie; \n",
            "\n",
            "I just had to jump in here as Carbonara is one of my favourites to make and ask \n",
            "what the hell are you supposed to use instead of cream?  I've never seen a \n",
            "recipe that hasn't used this.  Personally I use low fat creme fraiche because it \n",
            "works quite nicely but the only time I've seen an supposedly authentic recipe \n",
            "for carbonara  it was identical to mine (cream, eggs and lots of fresh parmesan) \n",
            "except for the creme fraiche.\n",
            "\n",
            "Stew\n",
            "-- \n",
            "Stewart Smith\n",
            "Scottish Microelectronics Centre, University of Edinburgh.\n",
            "http://www.ee.ed.ac.uk/~sxs/\n",
            "\n",
            "\n",
            "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
            "4 DVDs Free +s&p Join Now\n",
            "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
            "---------------------------------------------------------------------~->\n",
            "\n",
            "To unsubscribe from this group, send an email to:\n",
            "forteana-unsubscribe@egroups.com\n",
            "\n",
            " \n",
            "\n",
            "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ham\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvqvQw7HmU73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDPqBqg-vm_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgUBOeEcvx2w",
        "colab_type": "code",
        "outputId": "c05fa7e3-9394-4fd8-f191-76d360b24f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                   lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "max_length_of_text = 1000\n",
        "X = pad_sequences(X, maxlen=max_length_of_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 87037 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpU9X4WRv0ph",
        "colab_type": "code",
        "outputId": "88d473c4-dd77-457f-ad12-ea588bfc1029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   82,   55,  169],\n",
              "       [   0,    0,    0, ...,    1,  547, 1019],\n",
              "       [   0,    0,    0, ...,    1,  547, 1019],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  118,  407,  178],\n",
              "       [   0,    0,    0, ..., 8552, 7983,  652],\n",
              "       [  35,   92, 2725, ..., 1759,   38,  609]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {
        "id": "ExoCUkiBwFu0",
        "colab_type": "code",
        "outputId": "cdc28109-939c-4ef4-b336-bc99707570ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "y = Y\n",
        "print(y)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "y = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam']\n",
            "(3053, 2)\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMOwDOVUwoeR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, LSTM, Input, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvr1qkhpweu5",
        "colab_type": "code",
        "outputId": "02aff2e4-2812-4c11-a428-56b99ef47c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2442, 1000) (2442, 2)\n",
            "(611, 1000) (611, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cHOUqkpPwjLU",
        "colab_type": "code",
        "outputId": "69724543-22a3-42bf-af6a-700185dfd3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "embed_dim = 64\n",
        "lstm_out = 128\n",
        "batch_size = 64\n",
        "\n",
        "inputs = Input((max_length_of_text, ))\n",
        "x = Embedding(num_words, embed_dim)(inputs)\n",
        "x = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)(x)\n",
        "x = Dense(2,activation='sigmoid')(x)\n",
        "model = Model(inputs, x)\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 1000, 64)          640000    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 739,074\n",
            "Trainable params: 739,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WPBwot01wv4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ss2Exwftwzeo",
        "colab_type": "code",
        "outputId": "3d66dea0-534e-437c-fefe-089abfdbe633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size = batch_size, epochs = 3, validation_split = 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2197 samples, validate on 245 samples\n",
            "Epoch 1/3\n",
            "2197/2197 [==============================] - 77s 35ms/step - loss: 0.4724 - acc: 0.8234 - val_loss: 0.3016 - val_acc: 0.8612\n",
            "Epoch 2/3\n",
            "2197/2197 [==============================] - 75s 34ms/step - loss: 0.1433 - acc: 0.9545 - val_loss: 0.0849 - val_acc: 0.9837\n",
            "Epoch 3/3\n",
            "2197/2197 [==============================] - 74s 34ms/step - loss: 0.0436 - acc: 0.9904 - val_loss: 0.0671 - val_acc: 0.9796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23fc475668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "metadata": {
        "id": "hIcuzwUHw2HU",
        "colab_type": "code",
        "outputId": "a47653f7-cf33-43b8-a764-fb7e4659ab00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "score,acc = model.evaluate(X_test, y_test, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.2f\" % (acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "611/611 [==============================] - 5s 8ms/step\n",
            "Score: 0.03\n",
            "Validation Accuracy: 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ujqiFC5cxbRt",
        "colab_type": "code",
        "outputId": "3df4b5ab-239b-41ba-f131-5e27b4de7d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rVR0VkY9yTZp",
        "colab_type": "code",
        "outputId": "d0461064-10fc-40b3-ca6c-d2b5e2a3cd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11257
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(y_test))\n",
        "for i in y_test:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "611\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[0. 1.]\n",
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bHh2Kmcqz7A9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}